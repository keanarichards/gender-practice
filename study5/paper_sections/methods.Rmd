---
author: "Keana Richards"
date: "6/9/2020"
output:
  word_document: default
---

```{r, include = F}

## hiding code chunks globally 
knitr::opts_chunk$set(echo=FALSE, message = F, warning = F)


## limiting number of digits to 2 decimal places
options(digits = 2)
options(pillar.sigfig = 2)
options(repos="https://cran.rstudio.com" )
# load packages -----------------------------------------------------------
## Package names
packages <- c("readr", "tidyverse", "here", "summarytools")

## Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

## Packages loading
invisible(lapply(packages, library, character.only = TRUE))

clean <- read_csv(here("study5", "data", "clean.csv"))
excluded <- read_csv(here("study5", "data", "excluded.csv"))
dropped_out <- read_csv(here("study5", "data", "dropped_out.csv"))

clean_fraud_removed <- clean %>% filter(fraud == 0) 

```

## Participants

Participants were recruited on Amazon Mechanical Turk using the same screening criteria as all previous studies in Chapter 1. Like the last study of Chapter 1, we used Qualtrics’ fraud detection software to filter out responses that were suspicious either because they were likely 1) bots and/or 2) duplicate responses using the same exclusion criteria from before. These exclusions were applied for all main analyses reported in the results section. 

The final dataset consists of `r nrow(clean_fraud_removed)` participants (`r freq(clean_fraud_removed$gender, report.nas = F)[6]`% women), with an average age of `r mean(clean_fraud_removed$age, na.rm = T)` (*SD* = `r sd(clean_fraud_removed$age, na.rm = T)`) years. Of the final sample, `r nrow(dropped_out)` participants (`r freq(dropped_out$Gender...17, report.nas = F)[5]`% women) dropped out of the study before finishing and `r nrow(clean %>% filter(fraud ==1))` participants were flagged by Qualtrics' fraud detection software as suspicious based on the aforementioned criteria. We include analyses for the full sample in the appendix and all results are unchanged (INSERT DOUBLE CHECK). 

## Procedures 

Participants included in the study were told they would be completing a multiplication task. Notably, we aimed to recruit a larger sample to grant us enough power to detect our anticipated interaction effects, and decided to shorten the task from two minutes to 30 seconds. Otherwise, the task used was identical to the ones used in previous studies.

Like the studies in Chapter 1, participants were first told about the rules for the multiplication task and were required to pass the same comprehension questions used in the previous studies before moving onto the main manipulation of payment scheme.

### Manipulation of payment scheme 

Unlike previous studies, participants were not able to choose a payment scheme. Instead, they were told about their random assignment to one of two payment schemes: the non-competitive piece-rate payment scheme or a competitive tournament payment scheme. Men and women were evenly assigned to both conditions. If they were assigned to the piece-rate payment scheme, they were paid \$.10 per problem solved correctly. If they were assigned to the tournament payment scheme, they were randomly matched with another participant that was also assigned to that payment scheme and received $.20 per problem if they solved more problems than the other participant. Otherwise, they received nothing. 

Again, we checked that condition was assigned evenly across participants (control= `r freq(clean_fraud_removed$condition)[5]`%) and genders included in the study. Of the men who completed the study, `r ctable(clean_fraud_removed$gender, clean_fraud_removed$condition)$proportions[1]*100`% were assigned to the control condition and of the women who completed the study, `r ctable(clean_fraud_removed$gender, clean_fraud_removed$condition)$proportions[2]*100`% were assigned to the control condition. We also assessed condition-dependent attrition by identifying the number of participants that dropped out during/after learning about condition and find that a relatively small proportion of participants out of the total sample dropped out after learning about their respective condition (*N* = `r nrow(clean_fraud_removed %>% filter(Finished == "FALSE" & !is.na(condition)) %>% select(Finished, condition))`). Given the small sample that dropped out relative to the total number of participants in the study, we are not concerned that condition-dependent attrition is driving any of the effects found in this study. 

### Main dependent variables of interest: Measures of preparation and perceptions of relative preparation 

After they were informed of their payment scheme, all participants were given the opportunity to spend unlimited time preparing before completing the paid multiplication task. The nature of the unlimited preparation was identical to that used in Study 3 of Chapter 1, where participants who chose to prepare were shown 10 multiplication problems that were created randomly by drawing from the pool of numbers used in the main multiplication task. Unlike the last study in Chapter 1, participants were not asked to explicitly indicate whether they would like to study the times tables. Instead, they were shown the times table right after the practice problems directly on the practice problems page and told they could check their answers using the table as desired. By including the option to check their answers, we hoped to make the practice itself more useful by providing participants a way to receive feedback on their responses. At the bottom of each practice page, participants were asked if they would like to continue practicing multiplication problems, with the option to continue as many times as desired or opt out at any point. The amount of time (in seconds) participants spent on each practice page was also recorded. Thus, like the previous studies, we have multiple measures of preparation by design: 1) the actual decision to practice problems (before knowing what the practice entails), 2) among participants who chose to practice problems, the number of practice problems participants attempted (quantified as number of practice problems not left blank, irrespective of accuracy), 3) among participants who chose to practice problems, the amount of time they spent across all practice rounds they completed, and 4) the number of extra practice rounds participants completed after having completed the first round of practice. Again, the number of extra practice rounds serves as a way to quantify the number of times participants continue to practice after having seen what the practicing/studying looks like and having gone through it at least once. By encoding participants who both chose not to practice and those who chose not to continue practicing after the first round with zeroes in the dataset when creating this variable, we are able to separate out the effect of the choice to practice from the choice to continue practicing.  

After completing the practicing/studying, participants guessed how much their amount of practicing for the task compared to all other participants that completed the task by indicating the decile of their practice relative to other participants. We also asked participants to indicate their anticipated decile when their amount of practicing was compared to that of all participants who identified as men and women, respectively. 

We used these the decile questions to create the perceived practice deviation variables as follows: self-rated decile (either based on the question about practicing relative to all other participants, relative to only men, or relative to only women) - actual percentile based on number of practice problems completed. Therefore, negative values for this variable indicate a participant expected to have practiced less, relative to other participants, than they actually did, and vice versa for positive values. A value of zero, therefore, indicates that a given participant was completely accurate in their guess of relative practicing. 

### Paid multiplication task and post-task measures

After practicing, participants completed the paid multiplication task, received feedback about their absolute (but not relative) performance, and completed many of the same follow-up questions used across Chapter 1, including risk attitudes, confidence, and perceptions of gender differences in preparation, competitiveness, and performance. One of the perceptions of gender differences questions deviated slightly from the previous studies, which was edited for the sake of clarity. Instead of asking participants to indicate “Do you think men or women in this study chose the tournament payment option more often?”, they were asked "If given the opportunity to choose between the two payment schemes (Piece Rate or Tournament), do you think men in this study would choose the piece rate or the tournament payment scheme more often?", with the options to indicate: "Men would choose tournament more often than piece rate", "Men would choose piece rate more often than tournament", or "Men would choose each payment scheme equally". This question was repeated with respect to women in the study. 

We paid participants to answer the questions about their confidence and perceptions of gender differences correctly at the same rate as previous studies. Finally, they completed the same demographic questions from Chapter 1 and provided feedback on the study before being paid for their participation. 
