---
author: "Keana Richards"
date: "6/9/2020"
output:
  word_document: default
---

```{r, include = F}

## hiding code chunks globally 
knitr::opts_chunk$set(echo=FALSE, message = F, warning = F)


## limiting number of digits to 2 decimal places
options(digits = 2)
options(pillar.sigfig = 2)
options(repos="https://cran.rstudio.com" )
# load packages -----------------------------------------------------------
## Package names
packages <- c("readr", "tidyverse", "here", "summarytools", "papaja")

## Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

## Packages loading
invisible(lapply(packages, library, character.only = TRUE))

clean <- read_csv(here("study5", "data", "clean.csv"))
excluded <- read_csv(here("study5", "data", "excluded.csv"))
dropped_out <- read_csv(here("study5", "data", "dropped_out.csv"))

clean_fraud_removed <- clean %>% filter(fraud == 0) 
source(here("study5", "source", "03_exploratory-analyses.R"))

```

## Participants

Participants were recruited on Amazon Mechanical Turk using the same screening criteria as all previous studies in Chapter 1. Like the last study of Chapter 1, we used Qualtrics’ fraud detection software to filter out responses that were suspicious either because they were likely 1) bots and/or 2) duplicate responses using the same exclusion criteria from before. These exclusions were applied for all main analyses reported in the results section. 

The final dataset consists of `r nrow(clean_fraud_removed)` participants (`r freq(clean_fraud_removed$gender, report.nas = F)[6]`% women), with an average age of `r mean(clean_fraud_removed$age, na.rm = T)` (*SD* = `r sd(clean_fraud_removed$age, na.rm = T)`) years. Of the final sample, `r nrow(dropped_out)` participants (`r freq(dropped_out$Gender...17, report.nas = F)[5]`% women) dropped out of the study before finishing and `r nrow(clean %>% filter(fraud ==1))` participants were flagged by Qualtrics' fraud detection software as suspicious based on the aforementioned criteria. We include analyses for the full sample in the appendix and all results are unchanged (INSERT DOUBLE CHECK). 

## Procedures 

Participants included in the study were told they would be completing a multiplication task. Notably, we aimed to recruit a larger sample to provide enough power to detect our anticipated interaction effects, and shortened the task from two minutes (as in Chapter 1) to 30 seconds (in the present study). Otherwise, the task used was identical to the ones used in previous studies.

Like the studies in Chapter 1, participants were first told about the rules for the multiplication task and were required to pass the same comprehension questions used in the previous studies before moving onto the main manipulation of payment scheme.

### Manipulation of payment scheme 

Unlike previous studies, participants were not able to choose a payment scheme. Instead, they were told about their random assignment to one of two payment schemes: the non-competitive, piece-rate payment, scheme or a competitive, tournament, payment scheme. Men and women were evenly assigned to both conditions. If they were assigned to the piece-rate payment scheme, they were paid \$.10 per problem solved correctly. If they were assigned to the tournament payment scheme, they were randomly matched with another participant that was also assigned to that payment scheme and received $.20 per problem if they solved more problems than the other participant. Otherwise, they received nothing. 

Again, we checked that condition was assigned evenly across participants (control= `r freq(clean_fraud_removed$condition)[5]`%) and genders included in the study. Of the men who completed the study, `r ctable(clean_fraud_removed$gender, clean_fraud_removed$condition)$proportions[1]*100`% were assigned to the control condition and of the women who completed the study, `r ctable(clean_fraud_removed$gender, clean_fraud_removed$condition)$proportions[2]*100`% were assigned to the control condition, `r apa_print(sec_exploratory24, n = nrow(clean_fraud_removed))$statistic`. We also assessed condition-dependent attrition by identifying the number of participants that dropped out during/after learning about condition and found that a relatively small proportion of participants out of the total sample dropped out after learning about their respective condition (*N* = `r nrow(clean_fraud_removed %>% filter(Finished == "FALSE" & !is.na(condition)) %>% select(Finished, condition))`; INSERT N=XX men, N=XX women, chi-sq=xxx). Given the small sample that dropped out relative to the total number of participants in the study, we are not concerned that condition-dependent attrition is driving any of the effects found in this study. 

### Main dependent variables of interest: Measures of preparation and perceptions of relative preparation 

After they were informed of their payment scheme, all participants were given the opportunity to spend unlimited time preparing before completing the paid multiplication task. The nature of the unlimited preparation was identical to that used in Study 3 of Chapter 1, where participants who chose to prepare were shown 10 multiplication problems that were created randomly by drawing from the pool of numbers used in the main multiplication task. Unlike the last study in Chapter 1, participants were not asked to explicitly indicate whether they would like to study the times tables. Instead, they were shown the times table right after the practice problems directly on the practice problems page and told they could check their answers using the table as desired. By including the option to check their answers, we hoped to make the practice itself more useful by providing participants a way to receive feedback on their responses. At the bottom of each practice page, participants were asked if they would like to continue practicing multiplication problems, with the option to continue as many times as desired or opt out at any point. The amount of time (in seconds) participants spent on each practice page was also recorded. Thus, like the previous studies, we have multiple measures of preparation, by design: 1) the actual decision to practice problems (before knowing what the practice entails), 2) among participants who chose to practice problems, the number of practice problems participants attempted (quantified as number of practice problems not left blank, irrespective of accuracy), 3) among participants who chose to practice problems, the amount of time they spent across all practice rounds they completed, and 4) the number of extra practice rounds participants completed after having completed the first round of practice. Since the practice structure in this study is identical to that of Study 3 in Chapter 1, the number of extra practice variable was encoded in the same way as that study. 

After completing the practicing/studying, participants guessed how much their amount of practicing for the task compared to all other participants who completed the task by indicating the decile of their practice relative to other participants. We also asked participants to indicate their anticipated decile when their amount of practicing was compared to that of all participants who identified as men and women, respectively. 

We used these decile questions to create the perceived practice deviation variables as follows: self-rated decile (either based on the question about practicing relative to all other participants, relative to only men, or relative to only women) - actual percentile based on number of practice problems completed. Therefore, negative values for this variable indicate a participant expected to have practiced less, relative to other participants, than they actually did, and vice versa for positive values. A value of zero, therefore, indicates that a given participant was completely accurate in their guess of relative practicing. 

### Paid multiplication task and post-task measures

After practicing, participants completed the paid multiplication task, received feedback about their absolute (but not relative) performance, and completed many of the same follow-up questions used across Chapter 1, including risk attitudes, confidence, and perceptions of gender differences in preparation, competitiveness, and performance. Like Study 3 of Chapter 1, all questions had three response options (e.g., men are more likely to compete than women, women are more likely to compete than men, or there are no differences how much men or women would choose to compete). One of the perceptions of gender differences questions deviated slightly from the previous studies, which was edited for the sake of clarity. Instead of asking participants to indicate “Do you think men or women in this study chose the tournament payment option more often?”, they were asked "If given the opportunity to choose between the two payment schemes (Piece Rate or Tournament), do you think men in this study would choose the piece rate or the tournament payment scheme more often?", with the options to indicate: "Men would choose tournament more often than piece rate", "Men would choose piece rate more often than tournament", or "Men would choose each payment scheme equally". This question was repeated with respect to women in the study. 

We paid participants to answer the questions about their confidence and perceptions of gender differences correctly at the same rate as previous studies. Finally, they completed the same demographic questions from Chapter 1 and provided feedback on the study before being paid for their participation. 
