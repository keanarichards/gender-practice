---
title: "Study 1 methods"
author: "Keana Richards"
date: "6/9/2020"
output:
  word_document: default
---

```{r, include = F}

## hiding code chunks globally 
knitr::opts_chunk$set(echo=FALSE, message = F, warning = F)


## limiting number of digits to 2 decimal places
options(digits = 2)
options(pillar.sigfig = 2)
options(repos="https://cran.rstudio.com" )
# load packages -----------------------------------------------------------
## Package names
packages <- c("readr", "tidyverse", "here", "summarytools")

## Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

## Packages loading
invisible(lapply(packages, library, character.only = TRUE))

clean <- read_csv(here("study5", "data", "clean.csv"))
excluded <- read_csv(here("study5", "data", "excluded.csv"))
dropped_out <- read_csv(here("study5", "data", "dropped_out.csv"))

```

note to self: pulled from nsf app 01_project-description.Rmd


# Study 1: Does competition elicit gender differences in effort?

*Participants*

Participants will be recruited to complete a study on "decision-making and performance" through MTurk, with a guaranteed payment and the opportunity to earn bonuses depending on their performance and the performance of others. Recruiting participants on this platform allows for efficient data collection while meeting acceptable psychometric standards, such as high test-retest and alpha reliability [@Rand2012; @Buhrmester2011]. Since we anticipate completing the required parts of the study will take no more than 10 minutes on average, we will pay participants $2.50 (i.e., double the federal and Pennsylvania minimum wage), with the opportunity for bonuses, outlined below. Participants will only be included if they indicate that they are 18 years or older, are American citizens, and identify as female or male while answering initial demographic questions. 


Given the difficulty of powering interaction effects [see @Simonsohn2014; @Giner-Sorolla2018], we conducted a power analysis to determine an adequate sample size for the main hypothesized interaction effect in the primary analysis [simulations modeled after code from @Hughes2017a]. We ran 5000 simulations while varying the sample size (_N_ = 3000, 3250, 3500) and the effect size for the interaction effect (_b_ = .2, .3, .4). Based on these simulated estimates, we will recruit 3250 participants to achieve at least 80% power for a relatively small effect (_b_ = .2) (see Figure 3). 


```{r, fig.retina=NULL, out.width="300px"}
knitr::include_graphics(here("nsf-application", "nsf3.png"))


```

*Manipulation*

Participants will be randomly assigned to follow either a competitive or noncompetitive payment scheme for one round (2 minutes) of multiplication problems. The payment scheme will be manipulated between subjects, where participants in the competition (tournament) condition will be paid 4 cents per problem on the task, but only if they beat another randomly assigned MTurker, while participants assigned to the noncompetitive (piece-rate) payment scheme will be paid 2 cents per problem. Although a within-subjects design would provide more power in detecting the hypothesized interaction effect, we opted to use a between-subjects design to avoid carryover effects. If we followed a within-subjects design, we would only be able to confidently interpret the results for whichever condition were presented first because there would be several carryover effects that could affect the decision to prepare (e.g., fatigue and/or learning effects reducing participants' desire to prepare, demand effects for preparation if participants believe they are expected to prepare more in one condition compared to the other).

*Dependent variable* 

After participants in each condition are told which payment scheme they will be following, they will have the option to prepare for the task by completing unlimited practice problems, which they will be told could improve their performance on the subsequent task. To measure their desire to prepare for the task, we will first ask participants whether they would like to spend any time practicing multiplication problems. We chose a multiplication task because we expect participants will improve with practice. Indeed, research suggests that rehearsing and recalling associative memories can speed up retrieval of those memories [@Rundus1971]. Moreover, we have already established a robust gender difference in both the choice to prepare and compete using this task (Richards et al., in prep). For participants who agree to practice, they will be be able to practice for as long as they want, with the option to pause in case of any unexpected interruptions, such as children coming into the room. Also, participants will have the option to exit the preparation and move onto the task at any point via an "Exit" button in the bottom right corner of the survey screen. The dependent variable will be quantified as the total number of seconds of preparation, excluding the amount of time participants paused during the practice. 

*Task performance* 

After practicing, participants in each condition will complete the paid multiplication task. Participants' scores on the task will be quantified as the number of questions correct within the two-minute time frame allotted, without any penalties for incorrect responses. Afterwards, participants will be informed of the number of questions they answered correctly. We do not include any information about their relative performance since we ask them to guess their relative performance in the confidence measure. Thus, participants following the tournament payment scheme will not be told whether they won, since this serves as an indicator of relative performance. 


```{r}
source(here("study5", "source", "01_preregistered-analyses.R"))
```


*Post-manipulation measures* 

After completing the task, participants will complete a series of measures to be used for exploratory analyses. All questions will be counterbalanced. A confidence measure will incentivize participants to guess their relative performance compared to all other participants that completed the task by indicating the decile of their score relative to other participants. If correct, participants will earn $.25. We use a measure of relative performance, rather than a measure of absolute performance (e.g., asking participants to guess their score on the task) because perceptions of relative performance will likely be predictive of the choice to practice, especially when an individual is required to compete. The confidence measure draws from previous research [@Niederle2007], but instead of asking participants to indicate whether they won against a randomly selected opponent, we ask them to guess their relative decile to provide us with more information about their relative confidence. Given the difficulty of guessing one's exact percentile without any information about other participants, deciles are used rather than percentiles to make earning the bonus seem more achievable. Also, the item will be phrased so participants do not need to understand the word "decile," but will be asked "If my performance is compared to that of all participants that completed the task, I think my score was..." with the options for responses ranging from "Better than all other participants" to "Better than none of the other participants" with 10% increments in between (e.g., "Better than 50% of participants"). Since task-specific confidence measures tend to be better predictors of behavior than general measures of confidence [see @Oney2015 for review], the confidence measure assesses participants' beliefs within the context of the task used. We will also measure risk attitude by asking participants to indicate on a 0-10 scale "How do you see yourself: Are you generally a person who is fully prepared to take risks or do you try to avoid taking risks?" [@Dohmen2011b].  There is evidence that risky behavior (i.e., lottery choices) is strongly associated with the risk measure included in the current proposal [@Dohmen2011b]. Additionally, risk attitude tends to be explained by one underlying trait, with a relatively smaller amount of variation in risk attitude explained by context (e.g., risk attitude during career, health, or financial decisions). Thus, across contexts, risk attitude is likely to be stable and predictive of behavior [@Dohmen2011b]. These measures are included after completing the task largely because the confidence measure requires participants to state their perceived relative performance on the task. 

*Concerns: calculator use and attrition*

There may be concern that participants will use a calculator to answer the multiplication questions, which could affect the interpretation of the results if there is a gender difference in calculator use and/or calculator use is related to the choice to practice. Our previous work suggests participants are unlikely to use calculators to complete the task and more importantly, there are no gender differences in the choice to use a calculator. In our first study we ran using a multiplication task, participants who completed the task were asked i) whether they thought using a calculator would help them answer the multiplication problems more quickly and ii) whether they used a calculator to complete the multiplication task (they were told their response would not affect their payment). Based on their responses, it is unlikely that participants will use calculators in the first place, since `r round(prop.table(table(clean$calc1))[2]*100, digits =0)`% of participants indicated that they thought using a calculator to answer the multiplication questions would slow them down and `r round(prop.table(table(clean$calc2))[1]*100, digits =0)`% of participants said they did not use a calculator. Importantly, there were no gender differences in perceptions of how calculators would affect performance, `r apa_print(exploratory5a, n = nrow(clean))$statistic`. Additionally, we did not find evidence of gender differences in actual calculator use, `r apa_print(exploratory5b, n = nrow(clean))$statistic`. Since we are recruiting participants through the same platform using the same task in the current study, we expect these findings will generalize to the current study, and thus, do not have evidence that gender differences in calculator use will be a confound when interpreting our results.

Attrition can threaten an experiment's internal validity [@Zhou2016]. Fortunately, our previous work suggests that condition-dependent attrition is unlikely (Richards et al., in prep). In our prior study where participants completed one round of a similar multiplication task under each type of payment scheme, only a small proportion of participants (6%) dropped out during the study. And, of the participants who dropped out, all did so at the end of the study, after completing both of the main tasks. Nevertheless, we will still take several steps to counteract the possibility of condition-dependent attrition, which has the potential to lead to misleading conclusions [@Zhou2016], especially if women and men drop out of the study at different rates based on condition. First, we will employ three costless strategies (i.e., personalization, forewarning of study content, and an appeal to participants’ conscience) suggested by @Reips2000 and shown in @Zhou2016 to be effective in reducing dropout rates by at least half. When participants enter the study, they will read a message that serves as both a forewarning and an appeal to their conscious [modified from @Zhou2016]: “This is an anonymous survey consisting of multiple questions. If a sizable number of people quit a survey partway, the data quality of that survey would be compromised. However, our research depends on good quality data, so we ask that you are willing to participate in the survey for its entirety.” Then, participants will enter their MTurk ID as a means of establishing personalization. Notably, @Zhou2016 acknowledge that this is not a foolproof solution, since screening participants in advance in this way may reduce external validity. In this case, we want to have the capacity to establish the anticipated effect in the first place, so we are prioritizing internal validity. 


In addition to these preventive measures, we will collect information about the rates of attrition during each study. Turkprime provides a metric for the overall rate of attrition, while Qualtrics offers the option to view partial responses from dropouts. For participants who drop out during or after learning about the manipulation, we will create an indicator variable for survey completion based on partial responses from Qualtrics, which will be coded as 1 if participants finish the study and 0 otherwise. This indicator will then be submitted as the dependent variable to a logistic regression with $\beta_{0} + \beta_{1} \textrm{Gender}+ \beta_{2} \textrm{Condition} + \beta_{3} \textrm{Gender} \times \textrm{Condition}$ as predictors. If we find a significant interaction effect between gender and condition, this would suggest that we should interpret our results with caution because internal validity may be threatened, which will be explicitly stated in any reports on the studies, along with overall attrition rates and condition-dependent attrition rates [@Zhou2016].

*Primary hypotheses and analyses*

We will be using two-tailed tests during all hypothesis testing (_p_ < .05) and all analyses will be conducted using _R_. To control the false-discovery rate during exploratory analyses, we will apply the Benjamini-Hochberg correction to all exploratory analyses. All analyses will be pre-registered on Open Science Framework. 

We expect that women will choose to prepare more than men, especially before a competition. We will test the interaction between gender and condition (competitive or noncompetitive pay) using a linear regression with amount of time a participant chose to prepare (log-transformed) as the dependent variable. We will include the number of practice problems completed as a control for differences in participants' ability, along with a control for the total time participants spent pausing during the practice. Thus, the following linear regression will be run:

$\textrm{Log(Time Preparing)}=\beta_{0} + \beta_{1} \textrm{Gender}+ \beta_{2} \textrm{Condition} + \beta_{3} \textrm{Number of problems completed}+ \beta_{4} \textrm{Total pause time}  + \beta_{5} \textrm{Gender} \times \textrm{Condition}$, 

where the piece-rate payment scheme and men will be coded as the reference groups for Condition and Gender, respectively. A positive beta coefficient for the interaction term ($\beta_{5}$) would support our hypothesis, indicating that the effect of gender on time spent preparing is greater in the tournament condition. Additionally, we expect positive beta coefficients for the main effects of gender and condition, suggesting the women and participants following the competitive pay scheme spent more time preparing. Finally, we will check that participants from different demographic groups were successfully randomized equally to each condition by running four separate logistic regressions with age, race/ethnicity, education, and income predicting condition (e.g., $\textrm{Condition} = \beta_{0}+ \beta_{1}\textrm{Age}$). Since both proposed experiments include large sample sizes (_N_ = 3250), it is unlikely demographic variables will become exceptionally imbalanced across conditions to the extent that they will explain our observed effects [@Bowers2011]. However, we will control for any variables that were not successfully randomized if we find significant differences in demographics across groups.  


*Exploratory analyses* 

We will test whether the role of confidence or risk attitude on time spent preparing differs based on participant gender and condition. To this end, we will run separate multiple regression analyses to test whether confidence or risk attitude interact with gender and condition to affect time spent preparing (after log transformation) as the dependent variable. Therefore, the model will be structured as follows, where $X_{1}$ is either participants' confidence or risk attitude: 

$\textrm{Log(Time Preparing)}= \beta_{0}+ \beta_{1}  \textrm{Gender}+ \beta_{2} \textrm{Condition} + \beta_{3}  X_{1} + \beta_{4}  \textrm{Gender}\times \textrm{Condition}+ \beta_{5} \textrm{Condition} \times X_{1} + \beta_{6}  \textrm{Gender} \times X_{1} + \beta_{7}  \textrm{Gender} \times X_{1} \times \textrm{Condition}$. 

The reference groups will be the piece-rate payment scheme and men for condition and gender, respectively. Given the previous literature on gender gaps in confidence/risk attitude and competitiveness, we would expect a three-way interaction between gender, condition, and confidence/risk attitude on preparation, where women's confidence/risk plays a larger role in time spent preparing for women following the competitive payment scheme, relative to men following either the competitive or piece-rate payment scheme and women following the piece-rate payment scheme. A three-way interaction may be underpowered with the current sample size, so the analysis of the three-way interaction will serve as the foundation for future work using the effect sizes found.